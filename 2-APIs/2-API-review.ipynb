{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb3cef23-84b8-4dd8-82bb-90a24aeb1bfa",
   "metadata": {},
   "source": [
    "## Review Application Programing Interfaces (APIs) and JavaScript Object Notation (JSON) format\n",
    "Understanding how APIs work is crucial for those learning about AI, as APIs provide the standardized mechanisms for accessing and integrating AI models and services into applications. Being able to effectively interact with APIs enables learners to explore different AI offerings, leverage AI frameworks and libraries, and incorporate AI capabilities into a wide range of projects, which is an increasingly valuable skill as AI becomes more pervasive across various domains.<P>\n",
    "\n",
    "Additionally, familiarity with JSON (JavaScript Object Notation) is essential for students learning about AI, as this lightweight data format is widely used for request/response payloads in AI APIs, configuration files in AI frameworks, and the representation of input/output data for AI models. Understanding the structure and syntax of JSON allows students to seamlessly interact with AI-related tools and services, parse and manipulate the data used in AI applications, and facilitate the integration of AI components into larger, distributed systems - all of which are crucial skills for AI practitioners working in real-world, web-based environments.<P>\n",
    "\n",
    "Technically, here we are using a REST API. The use of RESTful (Representational State Transfer) APIs is highly relevant for students learning about AI, as REST has become the de facto standard for modern web services and APIs, including those used in AI-powered applications. REST APIs follow standardized principles and conventions, such as the use of HTTP methods for CRUD operations on resources, a resource-oriented design that aligns well with data-centric AI tasks, and the use of flexible data formats like JSON - all of which enable AI practitioners to easily integrate AI capabilities into their applications by leveraging a vast ecosystem of data sources, services, and tools through well-documented, stateless, and scalable API interfaces.\n",
    "### Table of Contents\n",
    "1. [GET()](#get)\n",
    "2. [JSON](#json)\n",
    "3. [Use a Real API](#api)\n",
    "4. [POST()](#post)\n",
    "5. [API Access Bedrock](#bedrock)\n",
    "6. [Assignment](#assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a105ab5-9dda-4b74-a733-d724dd160b54",
   "metadata": {},
   "source": [
    "## GET()<a name=\"get\"></a>\n",
    "The requests package is a popular library in Python for making HTTP requests to web servers. The get() and post() methods are two of the most commonly used functions provided by the requests library.\n",
    "\n",
    "The get() method is used to send an HTTP GET request to a specified URL. GET requests are typically used to retrieve data from a server, such as fetching a web page or an API response. The get() method returns a Response object, which contains the server's response, including the status code, headers, and the content of the response.\n",
    "\n",
    "`requests.get(url, params={}, args)`: <BR>\n",
    "This method sends a HTTP GET request to the specified URL. A GET request is used to retrieve data from a server. The params argument is an optional dictionary of query string arguments. The server responds by sending back the requested data. GET requests should only retrieve data and should have no other effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaeaded7-013c-4cba-a240-1dae9f2bcccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'login': 'darren-kraker',\n",
       " 'id': 48769318,\n",
       " 'node_id': 'MDQ6VXNlcjQ4NzY5MzE4',\n",
       " 'avatar_url': 'https://avatars.githubusercontent.com/u/48769318?v=4',\n",
       " 'gravatar_id': '',\n",
       " 'url': 'https://api.github.com/users/darren-kraker',\n",
       " 'html_url': 'https://github.com/darren-kraker',\n",
       " 'followers_url': 'https://api.github.com/users/darren-kraker/followers',\n",
       " 'following_url': 'https://api.github.com/users/darren-kraker/following{/other_user}',\n",
       " 'gists_url': 'https://api.github.com/users/darren-kraker/gists{/gist_id}',\n",
       " 'starred_url': 'https://api.github.com/users/darren-kraker/starred{/owner}{/repo}',\n",
       " 'subscriptions_url': 'https://api.github.com/users/darren-kraker/subscriptions',\n",
       " 'organizations_url': 'https://api.github.com/users/darren-kraker/orgs',\n",
       " 'repos_url': 'https://api.github.com/users/darren-kraker/repos',\n",
       " 'events_url': 'https://api.github.com/users/darren-kraker/events{/privacy}',\n",
       " 'received_events_url': 'https://api.github.com/users/darren-kraker/received_events',\n",
       " 'type': 'User',\n",
       " 'user_view_type': 'public',\n",
       " 'site_admin': False,\n",
       " 'name': None,\n",
       " 'company': None,\n",
       " 'blog': '',\n",
       " 'location': None,\n",
       " 'email': None,\n",
       " 'hireable': None,\n",
       " 'bio': None,\n",
       " 'twitter_username': None,\n",
       " 'public_repos': 0,\n",
       " 'public_gists': 0,\n",
       " 'followers': 0,\n",
       " 'following': 0,\n",
       " 'created_at': '2019-03-20T18:01:30Z',\n",
       " 'updated_at': '2025-04-05T21:09:25Z'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# example\n",
    "url = 'https://api.github.com/users/darren-kraker'\n",
    "response = requests.get(url)\n",
    "# Look at the json return from the API in json format\n",
    "json_response = response.json()\n",
    "# See all keys and values of the json\n",
    "json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539ef22-1524-4d30-950f-d2b45ea9c997",
   "metadata": {},
   "source": [
    "## JSON<a name=\"json\"></a>\n",
    "JSON (JavaScript Object Notation) is a lightweight data interchange format that is easy for humans to read and write, and easy for machines to parse and generate. It is often used for transmitting data between a server and web application or between different applications. In the context of Python programming and using Application Programming Interfaces (APIs), JSON plays a crucial role.\n",
    "\n",
    "When working with APIs, data is typically exchanged in a structured format, such as JSON or XML. JSON has become the preferred format due to its simplicity and the fact that it is natively supported in most programming languages, including Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2953017-f393-4ba8-b366-0aaa9ce3911d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Python, JSON is treated as a dictionary\n",
    "type(json_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1eee8ab-1b4f-4359-8720-1fdad3cdc302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "login\n",
      "id\n",
      "node_id\n",
      "avatar_url\n",
      "gravatar_id\n",
      "url\n",
      "html_url\n",
      "followers_url\n",
      "following_url\n",
      "gists_url\n",
      "starred_url\n",
      "subscriptions_url\n",
      "organizations_url\n",
      "repos_url\n",
      "events_url\n",
      "received_events_url\n",
      "type\n",
      "user_view_type\n",
      "site_admin\n",
      "name\n",
      "company\n",
      "blog\n",
      "location\n",
      "email\n",
      "hireable\n",
      "bio\n",
      "twitter_username\n",
      "public_repos\n",
      "public_gists\n",
      "followers\n",
      "following\n",
      "created_at\n",
      "updated_at\n"
     ]
    }
   ],
   "source": [
    "# We can look at the dict keys\n",
    "for k in json_response.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cafe82aa-eff6-4fda-9b67-4354a20877d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "darren-kraker\n",
      "48769318\n",
      "MDQ6VXNlcjQ4NzY5MzE4\n",
      "https://avatars.githubusercontent.com/u/48769318?v=4\n",
      "\n",
      "https://api.github.com/users/darren-kraker\n",
      "https://github.com/darren-kraker\n",
      "https://api.github.com/users/darren-kraker/followers\n",
      "https://api.github.com/users/darren-kraker/following{/other_user}\n",
      "https://api.github.com/users/darren-kraker/gists{/gist_id}\n",
      "https://api.github.com/users/darren-kraker/starred{/owner}{/repo}\n",
      "https://api.github.com/users/darren-kraker/subscriptions\n",
      "https://api.github.com/users/darren-kraker/orgs\n",
      "https://api.github.com/users/darren-kraker/repos\n",
      "https://api.github.com/users/darren-kraker/events{/privacy}\n",
      "https://api.github.com/users/darren-kraker/received_events\n",
      "User\n",
      "public\n",
      "False\n",
      "None\n",
      "None\n",
      "\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2019-03-20T18:01:30Z\n",
      "2025-04-05T21:09:25Z\n"
     ]
    }
   ],
   "source": [
    "# We can look at just the values\n",
    "for v in json_response.values():\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "941c478a-c6b9-44f6-a2ee-dfc148518781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MDQ6VXNlcjQ4NzY5MzE4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Of we know the key, we can see the value by using the ['key'] index\n",
    "json_response['node_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233de349-c5a6-4392-b085-2c23094bba76",
   "metadata": {},
   "source": [
    "## POST()<a name=\"post\"></a>\n",
    "The post() method, on the other hand, is used to send an HTTP POST request to a specified URL. POST requests are typically used to send data to a server, such as submitting a form or sending data to an API endpoint. The post() method also returns a Response object, which contains the server's response to the POST request. In this class, we will mostly use POST().<P>\n",
    "\n",
    "`requests.post(url, data={}, json={}, args)`:<BR>\n",
    "This method sends a HTTP POST request to the specified URL. A POST request is used to send data to a server to create a new resource. The data or json argument is a dictionary of data that you want to send to the server. The server responds by sending back data, often the details of the created resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6716fe44-7cb2-415a-b9f2-0c9719d8970b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the data I am sending...: {\"key1\": \"value1\", \"key2\": \"value2\"}\n",
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Example of POST()\n",
    "\n",
    "# Define the URL\n",
    "url = 'https://httpbin.org/post'\n",
    "\n",
    "# Define the headers\n",
    "headers = {\n",
    "    # If an API key is needed, put it here in the headers\n",
    "    # 'x-api-key': api_key,\n",
    "    'Content-Type': 'application/json',  # Inform the server about the type of the content\n",
    "    'Accept': 'application/json'  # Tell the server what we are expecting in the response\n",
    "}\n",
    "\n",
    "# Define the data you want to send\n",
    "data = {\n",
    "    'key1': 'value1',\n",
    "    'key2': 'value2'\n",
    "}\n",
    "\n",
    "# Convert the data to JSON format\n",
    "data_json = json.dumps(data) # Convert the dictionary to a json string 'dump string'\n",
    "print('Here is the data I am sending...:', data_json)\n",
    "\n",
    "# Send the POST request\n",
    "response = requests.post(url, headers=headers, data=data_json)\n",
    "\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    # Take action here\n",
    "    print('The API call was successful.')\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n",
    "# I usually don't print the response in this cell. This cell is only for making the API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df4f50eb-c7f2-4b04-bc79-1f6ccd39f1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args : {}\n",
      "data : {\"key1\": \"value1\", \"key2\": \"value2\"}\n",
      "files : {}\n",
      "form : {}\n",
      "headers : {'Accept': 'application/json', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '36', 'Content-Type': 'application/json', 'Host': 'httpbin.org', 'User-Agent': 'python-requests/2.32.3', 'X-Amzn-Trace-Id': 'Root=1-67f6f037-0dfcf5a03e96cf9d3b39cd15'}\n",
      "json : {'key1': 'value1', 'key2': 'value2'}\n",
      "origin : 129.65.145.119\n",
      "url : https://httpbin.org/post\n"
     ]
    }
   ],
   "source": [
    "# Iterate though the response json object and print the keys & values\n",
    "for key in response.json().keys():\n",
    "    print(key, ':',response.json()[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358400d-fc7d-461b-bd86-f9f818d908c7",
   "metadata": {},
   "source": [
    "### Storing API Keys "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ba64f0-56be-43d2-bcb4-12b1435d90a0",
   "metadata": {},
   "source": [
    "To store your API key for use within a notebook or other source code:\n",
    "- Get the access keys and secret from your email or other API vendor\n",
    "- Now, open a terminal from the jupyter Launcher\n",
    "    - Use the nano text editor (or any other editor)\n",
    "    - Create a .env file (that is a file with the exact name \".env\" (files that start with '.' are hidden by default\n",
    "    - Add a line that looks like this:\n",
    "       -   AWS_ACCESS_KEY_ID=\"YOUR_KEY\"\n",
    "       -   AWS_SECRET_ACCESS_KEY=\"YOUR_SECRET\"\n",
    "    - Insert your key in double-quotes\n",
    "    - Save the file and exit the text editor. In nano: Save (ctl-o), Exit (ctl-x)\n",
    "\n",
    "<P>\n",
    "Next we will load this key into this session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b053ff70-bb51-4b76-84ba-88a8ab9a5f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AKIAWWVMBM7ELQ5VQ65M\n",
      "VBAezTxIEpsMHQ+4dUfB7qNxoI1Vy5nPVn2E44jC\n"
     ]
    }
   ],
   "source": [
    "# If you want to use an API key or your access key load the following\n",
    "# This package may not installed in our Sagemaker image.\n",
    "# Everytime you researt this jupyterlab, you will have to reinstall it.\n",
    "#%pip install python-dotenv -q\n",
    "# Now import the objects we need\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# Now you can access the environment variable\n",
    "AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "# You can print the key to make sure it is there, but I get nervous when I see a key printed somewhere.... Someone could steal it!\n",
    "print(AWS_ACCESS_KEY_ID)\n",
    "print(AWS_SECRET_ACCESS_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f24406-14c3-4b56-9be7-2f62f686788e",
   "metadata": {},
   "source": [
    "## Use Bedrock API<a name=\"bedrock\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed35aaf1-ed48-434d-8ab4-ea9489b589fb",
   "metadata": {},
   "source": [
    "Amazon Bedrock simplifies the process of building and scaling generative AI applications by providing access to high-performing foundation models (FMs) from leading AI companies through a single API. \n",
    "\n",
    "Amazon Bedrock currently supports 9 different model providers. To see and updated list of providers or to use a particular foundation model with the Amazon Bedrock API, you'll need its model ID. For a list for providers and model IDs, see [Amazon Bedrock model IDs].(https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b584be98-5223-4a66-ab97-027bc22348e0",
   "metadata": {},
   "source": [
    "This function establishes a connection with AWS through your notebook to talk directly to Bedrock.  If you want to run this code in your VS Code environment you would need to add your IAM Access Key and Secret as shown below:<br/>\n",
    "<code>AWS_ACCESS_KEY_ID=\"YOUR_KEY\"\n",
    "AWS_SECRET_ACCESS_KEY=\"YOUR_SECRET\"\n",
    "bedrock_runtime = get_bedrock_client(True,AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d63b68c-bdba-423b-9407-1e8b8a4ccd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Built-Ins:\n",
    "import os\n",
    "from typing import Optional\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "import botocore\n",
    "\n",
    "def get_bedrock_client(\n",
    "    runtime: Optional[bool] = True,\n",
    "    aws_access_key_id: Optional[str] = None,\n",
    "    aws_secret_access_key: Optional[str] = None,\n",
    "    aws_session_token: Optional[str] = None\n",
    "):\n",
    "    if runtime:\n",
    "        service_name = 'bedrock-runtime'\n",
    "    else:\n",
    "        service_name = 'bedrock'\n",
    "\n",
    "    bedrock_runtime = boto3.client(\n",
    "        service_name=service_name,\n",
    "        region_name=\"us-west-2\",  # Change to your preferred region\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        aws_session_token=aws_session_token  # Optional\n",
    "    )\n",
    "\n",
    "    print(\"boto3 Bedrock client successfully created!\")\n",
    "    print(bedrock_runtime._endpoint)\n",
    "    return bedrock_runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bf9072-70a7-4fc4-9741-e0aa4db2c6ca",
   "metadata": {},
   "source": [
    "Now let's call our function and create an object that we can use to interact with Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb42aa8-cc6f-4541-bc56-2778fc8d0a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you are running in VS Code\n",
    "# bedrock_runtime = get_bedrock_client(True,AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)\n",
    "\n",
    "bedrock_runtime = get_bedrock_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd22730-7ef0-4047-b399-909ca335c47a",
   "metadata": {},
   "source": [
    "This function will be an abstract way to make our call to an LLM.  We will parameritize all the elements that change from model to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f6d00-fbf6-4e2d-9910-f8d35d2186d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_model(body, model_id, accept, content_type):\n",
    "    \"\"\"\n",
    "    Invokes Amazon bedrock model to run an inference\n",
    "    using the input provided in the request body.\n",
    "    \n",
    "    Args:\n",
    "        body (dict): The invokation body to send to bedrock\n",
    "        model_id (str): the model to query\n",
    "        accept (str): input accept type\n",
    "        content_type (str): content type\n",
    "    Returns:\n",
    "        Inference response from the model.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            body=json.dumps(body), \n",
    "            modelId=model_id, \n",
    "            accept=accept, \n",
    "            contentType=content_type\n",
    "        )\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Model invocation took {elapsed_time:.3f} seconds.\")\n",
    "\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Couldn't invoke {model_id}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cbcccf-e9f7-4e8d-9865-59efd074c99f",
   "metadata": {},
   "source": [
    "Now that we understand how to use an API, let's call some models using the Bedrock API!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89ec1ff-40e8-41e8-9725-6de75009271c",
   "metadata": {},
   "source": [
    "## Amazon Nova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674370e5-6b84-4dc9-8ef7-70d2df14c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you'd like to try your own prompt, edit this parameter!\n",
    "prompt_data = \"\"\"Command: Write a paragraph why Generative AI is an important technology to understand.\n",
    "\"\"\"\n",
    "\n",
    "# Define one or more messages using the \"user\" and \"assistant\" roles.\n",
    "message_list = [{\"role\": \"user\", \"content\": [{\"text\": prompt_data}]}]\n",
    "\n",
    "# Configure the inference parameters.\n",
    "inf_params = {\"max_new_tokens\": 250, \"top_p\": 0.9, \"top_k\": 20, \"temperature\": 0.7}\n",
    "\n",
    "body = {\n",
    "    \"schemaVersion\": \"messages-v1\",\n",
    "    \"messages\": message_list,\n",
    "    \"inferenceConfig\": inf_params,\n",
    "}\n",
    "# Note the us. allows cross region inference\n",
    "modelId = \"us.amazon.nova-lite-v1:0\"\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = invoke_model(body, modelId, accept, contentType)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body.get(\"output\").get(\"message\").get(\"content\")[0].get(\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9418c6",
   "metadata": {},
   "source": [
    "12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20fde14-c8b4-4c01-815e-72e99f30d95b",
   "metadata": {},
   "source": [
    "### Anthropic Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd7d4a1-774e-4cab-ac4c-e9b9a3f212ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you'd like to try your own prompt, edit this parameter!\n",
    "prompt_data = \"\"\"Human: Command: Write a paragraph why Generative AI is an important technology to understand.\n",
    "Assistant:\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": prompt_data}]Write a paragraph why Generative AI is an important technology to understand.\n",
    "\n",
    "body={\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 250,\n",
    "        \"messages\": messages\n",
    "    }\n",
    "\n",
    "modelId = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"  # change this to use a different version from the model provider\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = invoke_model(body, modelId, accept, contentType)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body.get(\"content\")[0].get(\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52da04b9-8581-4888-86aa-c46420e8bcd4",
   "metadata": {},
   "source": [
    "### Meta Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a6931f-5426-4eba-a4b1-3310ef69b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you'd like to try your own prompt, edit this parameter!\n",
    "prompt_data = \"\"\"\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "Write a paragraph why Generative AI is an important technology to understand.\"\"\"\n",
    "\n",
    "body = {\n",
    "    \"prompt\": prompt_data,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_p\": 0.9,\n",
    "    \"max_gen_len\": 512,\n",
    "}\n",
    "\n",
    "modelId = \"meta.llama3-8b-instruct-v1:0\"\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = invoke_model(body, modelId, accept, contentType)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body[\"generation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf3ae2b-ccac-4b4a-af7a-846cbe45770d",
   "metadata": {},
   "source": [
    "### Stability Stable Diffusion XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050e5e4c-ccc3-490d-803c-c4ca2a2f6534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you'd like to try your own prompt, edit this parameter!\n",
    "prompt_data = \"a horse riding an astronuat\"\n",
    "\n",
    "body = {\n",
    "    \"text_prompts\": [{\"text\": prompt_data}],\n",
    "    \"cfg_scale\": 10,\n",
    "    \"seed\": 20,\n",
    "    \"steps\": 50\n",
    "}\n",
    "modelId = \"stability.stable-diffusion-xl-v1\"\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "\n",
    "response = invoke_model(body, modelId, accept, contentType)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body[\"result\"])\n",
    "print(f'{response_body.get(\"artifacts\")[0].get(\"base64\")[0:80]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b783680-802e-4a6c-bb9f-bb07143ef75c",
   "metadata": {},
   "source": [
    "The output is a base64 encoded string of the image data. You can use any image processing library (such as Pillow) to decode the image as in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d05f95d-4d30-4d82-a42b-748351170a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "base_64_img_str = response_body.get(\"artifacts\")[0].get(\"base64\")\n",
    "image = Image.open(io.BytesIO(base64.decodebytes(bytes(base_64_img_str, \"utf-8\"))))\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09668b72-911f-426d-9c27-42926100b33a",
   "metadata": {},
   "source": [
    "Okay now lets explore how we can pass parameters to a prompt to get dynamic output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7902a7d4-b6b2-4f27-8abe-c60354bb8561",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_used_in_prompt = \"red\"\n",
    "\n",
    "prompt_data = f\"Human: Give me a few fruits that are the color {variable_used_in_prompt}. Assistant:\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": prompt_data}]\n",
    "\n",
    "body={\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 500,\n",
    "        \"messages\": messages\n",
    "    }\n",
    "\n",
    "modelId = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"  # change this to use a different version from the model provider\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = invoke_model(body, modelId, accept, contentType)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "print(response_body.get(\"content\")[0].get(\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fee1102-1a50-4bdc-86ec-01673ac3692a",
   "metadata": {},
   "source": [
    "## Assignment<a name=\"assignment\"></a>\n",
    "Use an API to gather data and pass that to an LLM to get a dynamic response.    \n",
    "Some possible API sources<br/>\n",
    "https://www.api-ninjas.com/api/ <br/>\n",
    "https://zenquotes.io/api/quotes/ <br/>\n",
    "\n",
    "Bonus: Try to extend your code to use models that fall outside Bedrock like OpenAI.<br/>\n",
    "<em>Note: LLMs external to Bedrock may require paying for an API key</em>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsb570env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
