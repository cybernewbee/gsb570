{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dff95dd0-f637-4d68-8746-8583fd081426",
   "metadata": {},
   "source": [
    "### Agents\n",
    "Agents will provide a way for us to add additional sources of information that will build on our RAG approach.  We may need to execute code or search different information sources to build a complex context to answer user queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0ae526-97d7-40d2-b8df-5a32aa379b53",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1074ae1c-f5d2-45e4-b5ee-09b61258c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain_community -q\n",
    "# %pip install tavily-python -q\n",
    "# %pip install python-dotenv -q\n",
    "# %pip install langchainhub -q\n",
    "%pip install wikibase-rest-api-client mediawikiapi -q\n",
    "%pip install yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74983e12-a639-4764-8d41-5088e721a21b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b440d19-08bc-4f7e-be3f-f5f28b77c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.tools.wikidata.tool import WikidataAPIWrapper, WikidataQueryRun\n",
    "from langchain_community.tools.yahoo_finance_news import YahooFinanceNewsInput\n",
    "from langchain.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain import hub\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# Create the AWS client for the Bedrock runtime with boto3\n",
    "aws_client = boto3.client(service_name=\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4030cbbf-2631-4dbf-9d85-e88e848e7de6",
   "metadata": {},
   "source": [
    "### Agent Setup\n",
    "We need three components to make up our agent\n",
    "1) Tools we plan to use to execute respond to input\n",
    "2) LLM we plan to use as our logic executor\n",
    "3) Agent type we plan to use for this use case\n",
    "\n",
    "#### Tavily Search\n",
    "Tavily's Search API is a search engine built specifically for AI agents (LLMs) that LangChain supports as a library import.\n",
    "\n",
    "*Note: This tool requires an API Key that will be loaded in your .env file as follows*.  \n",
    "\n",
    ">TAVILY_API_KEY=tvly-XXXXXXXXXXXXXXXXXXX\n",
    "\n",
    "To exectute this notebook [visit](https://app.tavily.com/) for an API key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b04a1-83f0-47a1-b4cc-511d7e960a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = os.getenv('TAVILY_API_KEY')\n",
    "print(\"API=\",test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f62d9-b7f9-4b1a-9aa8-e1c94dcb6a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Start with a simple web search tool:\n",
    "tools = [TavilySearchResults(max_results=1, TAVILY_API_KEY = os.getenv('TAVILY_API_KEY'))]\n",
    "\n",
    "# 2 LLM, Let's use Claude's Haiku\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "# Grab our LLM of choice\n",
    "model_kwargs =  { \n",
    "    \"max_tokens\": 2048,\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 0.9,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "}\n",
    "llm = BedrockChat(\n",
    "    client=aws_client,\n",
    "    model_id=model_id,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "# Get the prompt to use with our agent\n",
    "# The hub provides sample templates for each agent type\n",
    "prompt = hub.pull(\"hwchase17/structured-chat-agent\")\n",
    "\n",
    "\n",
    "#print(\"Tools:\", tools)\n",
    "#print(\"Prompt\", prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5de280-f4ae-4faf-94b2-84c09c83e8a5",
   "metadata": {},
   "source": [
    "#### Our logic prompt\n",
    "Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
    "\n",
    "Valid \"action\" values: \"Final Answer\" or {tool_names}\n",
    "\n",
    "Provide only ONE action per $JSON_BLOB, as shown:\n",
    "\n",
    "```\n",
    "\n",
    "{{\n",
    "\n",
    "  \"action\": $TOOL_NAME,\n",
    "\n",
    "  \"action_input\": $INPUT\n",
    "\n",
    "}}\n",
    "\n",
    "```\n",
    "\n",
    "Follow this format:\n",
    "\n",
    "Question: input question to answer\n",
    "\n",
    "Thought: consider previous and subsequent steps\n",
    "\n",
    "Action:\n",
    "\n",
    "```\n",
    "\n",
    "$JSON_BLOB\n",
    "\n",
    "```\n",
    "\n",
    "Observation: action result\n",
    "\n",
    "... (repeat Thought/Action/Observation N times)\n",
    "\n",
    "Thought: I know what to respond\n",
    "\n",
    "Action:\n",
    "\n",
    "```\n",
    "\n",
    "{{\n",
    "\n",
    "  \"action\": \"Final Answer\",\n",
    "\n",
    "  \"action_input\": \"Final response to human\"\n",
    "\n",
    "}}\n",
    "\n",
    "Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a293eeb-62ab-4f6a-a25f-92792e96dbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Construct the create_structured_chat_agent agent\n",
    "# https://python.langchain.com/v0.1/docs/modules/agents/agent_types/\n",
    "agent = create_structured_chat_agent(llm, tools, prompt)\n",
    "\n",
    "# run the agent\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True, handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "agent_executor.invoke({\"input\": \"What happened to the economy historically when tariffs were added to US imports?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9732bf3-0713-4fe5-8004-278588d7e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_executor.invoke({\"input\": \"Hi my name is Darren\"})\n",
    "last_input = response['input']\n",
    "last_output = response['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53036bdb-3880-4242-bc63-574ecc1494a9",
   "metadata": {},
   "source": [
    "#### Can agents keep track of our conversation and use the context?\n",
    "If we save the results, LangChain supports chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b806323a-dc44-46e5-81ca-37d504341262",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_executor.invoke({\"input\": \"What's my name?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7e9439-dd24-420d-ad44-4efe719fdcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_executor.invoke({\"input\": \"What's my name?\", \n",
    "                                  \"chat_history\": [\n",
    "                                        HumanMessage(content=last_input),\n",
    "                                        AIMessage(content=last_output),\n",
    "                                                  ],})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd308f4-f31b-42e4-af75-8464037a104e",
   "metadata": {},
   "source": [
    "#### Wiki Data Tool\n",
    "Let's add anther tool and observe how our Agent can use both tools to answer input questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39400f7-9b7e-43ae-9d5f-30fb8b9f4709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New tool WikiData\n",
    "wikidata = WikidataQueryRun(api_wrapper=WikidataAPIWrapper())\n",
    "# Add WikiData and Search Results\n",
    "tools = [wikidata, TavilySearchResults(max_results=1, TAVILY_API_KEY = os.getenv('TAVILY_API_KEY'))]\n",
    "agent = create_structured_chat_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True, handle_parsing_errors=True\n",
    ")\n",
    "agent_executor.invoke({\"input\": \"Who was the historical figure named Richard Feynman?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b884f1-62dd-4700-8be0-ca1d58df28fa",
   "metadata": {},
   "source": [
    "Now let's review our original question and see how the agent responds to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdb2da4-953c-423f-9fa7-60fce713dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"What happened to the economy historically when tariffs were added to US imports?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babc3d3e-40d1-4914-9ce1-84023fd5f504",
   "metadata": {},
   "source": [
    "#### Homework\n",
    "Use the [langchain tool](https://python.langchain.com/api_reference/community/tools.html) list to find a useful tool other than Wikidata or Tavily to explore what it can do "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1367abc-00c9-4ddd-9255-f5fc7a516d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your tool here\n",
    "# 1 Start with a simple web search tool:\n",
    "#tools = -> FIND A GOOD TOOL\n",
    "\n",
    "\n",
    "# 2 LLM, Let's use Claude's Haiku\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "# Grab our LLM of choice\n",
    "model_kwargs =  { \n",
    "    \"max_tokens\": 2048,\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 0.9,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "}\n",
    "llm = BedrockChat(\n",
    "    client=aws_client,\n",
    "    model_id=model_id,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "# Get the prompt to use with our agent\n",
    "# The hub provides sample templates for each agent type\n",
    "prompt = hub.pull(\"hwchase17/structured-chat-agent\")\n",
    "\n",
    "# 3 Construct the create_structured_chat_agent agent\n",
    "# https://python.langchain.com/v0.1/docs/modules/agents/agent_types/\n",
    "agent = create_structured_chat_agent(llm, tools, prompt)\n",
    "\n",
    "# run the agent\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True, handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "agent_executor.invoke({\"input\": \"What happened with the economy today?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
