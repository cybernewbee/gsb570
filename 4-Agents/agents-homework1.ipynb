{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dff95dd0-f637-4d68-8746-8583fd081426",
   "metadata": {},
   "source": [
    "### Agents\n",
    "Agents will provide a way for us to add additional sources of information that will build on our RAG approach.  We may need to execute code or search different information sources to build a complex context to answer user queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0ae526-97d7-40d2-b8df-5a32aa379b53",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1074ae1c-f5d2-45e4-b5ee-09b61258c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_community -q\n",
    "%pip install tavily-python -q\n",
    "%pip install python-dotenv -q\n",
    "%pip install langchainhub -q\n",
    "%pip install wikibase-rest-api-client mediawikiapi -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74983e12-a639-4764-8d41-5088e721a21b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b440d19-08bc-4f7e-be3f-f5f28b77c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.tools.wikidata.tool import WikidataAPIWrapper, WikidataQueryRun\n",
    "from langchain.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain import hub\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# Create the AWS client for the Bedrock runtime with boto3\n",
    "aws_client = boto3.client(service_name=\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4030cbbf-2631-4dbf-9d85-e88e848e7de6",
   "metadata": {},
   "source": [
    "### Agent Setup\n",
    "We need three components to make up our agent\n",
    "1) Tools we plan to use to execute respond to input\n",
    "2) LLM we plan to use as our logic executor\n",
    "3) Agent type we plan to use for this use case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459effca-b19c-4e0e-ae1b-04c273c3e31f",
   "metadata": {},
   "source": [
    "#### Homework\n",
    "Find a useful tool other than Wikidata or Tavily to explore what it can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6482a868-fcf4-4207-9d7b-8b18482d9d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your tool here\n",
    "# 1 Start with a simple web search tool:\n",
    "#tools = -> FIND A GOOD TOOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f62d9-b7f9-4b1a-9aa8-e1c94dcb6a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 LLM, Let's use Claude's Haiku\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "# Grab our LLM of choice\n",
    "model_kwargs =  { \n",
    "    \"max_tokens\": 2048,\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 0.9,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "}\n",
    "llm = BedrockChat(\n",
    "    client=aws_client,\n",
    "    model_id=model_id,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "\n",
    "# Get the prompt to use with our agent\n",
    "# The hub provides sample templates for each agent type\n",
    "prompt = hub.pull(\"hwchase17/structured-chat-agent\")\n",
    "\n",
    "# print(\"Tools:\", tools)\n",
    "# print(\"Prompt\", prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8f2005-01f2-4478-bef9-e53cc82134e0",
   "metadata": {},
   "source": [
    "Using your new tool see if you can get the expected output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a293eeb-62ab-4f6a-a25f-92792e96dbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Construct the create_structured_chat_agent agent\n",
    "# https://python.langchain.com/v0.1/docs/modules/agents/agent_types/\n",
    "agent = create_structured_chat_agent(llm, tools, prompt)\n",
    "\n",
    "# run the agent\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True, handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "agent_executor.invoke({\"input\": \"What happened with the economy today?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16994298-44e6-4e99-b84c-c7675855da26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
